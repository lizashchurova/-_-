{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KAl3CGWrE0ZG"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f400cc73824474c9bf53feb8109231a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_632818bb84944ecd80e431818905d211",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac033afaa43e47ceb405a43a247de384",
              "IPY_MODEL_f9cd6248cd08477aa114e728a2ba54cf"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "632818bb84944ecd80e431818905d211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "ac033afaa43e47ceb405a43a247de384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0fc0f3d83c2948878028cc0eeed63e03",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 203415,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 203415,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8cf936f1c53411bb5c06b372011ac68"
          },
          "model_module_version": "1.5.0"
        },
        "f9cd6248cd08477aa114e728a2ba54cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_338d781a47184a669238bcd05a798619",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 203415/203415 [11:06&lt;00:00, 305.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e87b54dbd0754b7ebd932f5507cf32b1"
          },
          "model_module_version": "1.5.0"
        },
        "0fc0f3d83c2948878028cc0eeed63e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d8cf936f1c53411bb5c06b372011ac68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "338d781a47184a669238bcd05a798619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e87b54dbd0754b7ebd932f5507cf32b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cl2kmVbltgE"
      },
      "source": [
        "# Объединение аннотаций для дублирующихся файлов в REALEC\n",
        "\n",
        "В корпусе REALEC много студенческих учебных текстов на английском языке, и иногда случается, что один и тот же текст заносится в корпус дважды и аннотируется дважды. В рамках этого задания предлагается автоматизировать слияние различающихся аннотаций для таких текстов в один файл и вывести таблицу конфликтов для аннотаций, которые перекрываются."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAl3CGWrE0ZG"
      },
      "source": [
        "### Подготовка среды\n",
        "\n",
        "Много полезных функций, все из которых подготавливают рабочее пространство для выполнения задания. Выполняются где-то около 15 минут, так что можно заварить кофе и посмотреть пару видео на ютубе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO2X79RLeant",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bfeb37-3a2d-4a02-be88-f8eb6a646248"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CU55Nqp3Y-"
      },
      "source": [
        "Скачиваем специально написанную мной библиотеку для обработки используемого в REALEC типа нотации ошибок в файлах `.ann`, основанного на `brat`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZLaBxuS8o7C"
      },
      "source": [
        "!git clone --quiet https://github.com/isikus/corpora-manipulation\n",
        "!cp ./corpora-manipulation/* ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791D28AUd6FS"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from collections import OrderedDict\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from realec_brat_to_patch_list import ann_to_patchlist\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_PS9RN4kTPx"
      },
      "source": [
        "Скачиваем актуальный дамп корпуса напрямую из REALEC. По опыту, это занимает либо 15 секунд, либо 6 минут – без третьего варианта. Так что как повезёт:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5dY9G2teBVM",
        "outputId": "d5ccd7d2-e6c1-4d7c-f061-9a274b6ff018"
      },
      "source": [
        "dataset = keras.utils.get_file(\n",
        "    fname=\"data.tar.gz\", \n",
        "    origin=\"http://realec.org/ajax.cgi?action=downloadCollection&collection=%2F&protocol=1\", \n",
        "    extract=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://realec.org/ajax.cgi?action=downloadCollection&collection=%2F&protocol=1\n",
            "77340672/Unknown - 21s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3u_ZLEPgkfYW",
        "outputId": "1e455c0b-b37e-416d-d7cb-698f348cfca7"
      },
      "source": [
        "shutil.copytree(\"/root/.keras/datasets/data\",\"./data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MQflkS7G3zB",
        "outputId": "ce972c07-549b-4335-d6da-9a890582b7a9"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1-VQnTAqTuB"
      },
      "source": [
        "#### Обработка корпуса\n",
        "\n",
        "В REALEC существует множество типов ошибок, которые структурированы в иерархическое многоуровневое дерево. В последующей скрытой ячейке мы записываем их, чтобы убрать из рассматриваемых текстов аннотации частей речи (их добавим позднее) и невалидные ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_dxJFul720o"
      },
      "source": [
        "#@title Список кодов типов ошибок\n",
        "error_typify = {\n",
        "  \"Punctuation\": \"Punctuation\",\n",
        "  \"Spelling\": \"Spelling\",\n",
        "  \"Capitalisation\": \"Spelling\",\n",
        "  \"Grammar\": \"Word-level grammar\",\n",
        "  \"Determiners\": \"Word-level grammar\",\n",
        "  \"Articles\": \"Word-level grammar\",\n",
        "  \"Quantifiers\": \"Word-level grammar\",\n",
        "  \"Verbs\": \"Word-level grammar\",\n",
        "  \"Tense\": \"Word-level grammar\",\n",
        "  \"Tense_choice\": \"Word-level grammar\",\n",
        "  \"Tense_form\": \"Word-level grammar\",\n",
        "  \"Voice\": \"Word-level grammar\",\n",
        "  \"Modals\": \"Word-level grammar\",\n",
        "  \"Verb_pattern\": \"Word-level grammar\",\n",
        "  \"Intransitive\": \"Word-level grammar\",\n",
        "  \"Transitive\": \"Word-level grammar\",\n",
        "  \"Reflexive_verb\": \"Word-level grammar\",\n",
        "  \"Presentation\": \"Word-level grammar\",\n",
        "  \"Ambitransitive\": \"Word-level grammar\",\n",
        "  \"Two_in_a_row\": \"Word-level grammar\",\n",
        "  \"Verb_Inf\": \"Word-level grammar\",\n",
        "  \"Verb_Gerund\": \"Word-level grammar\",\n",
        "  \"Verb_Inf_Gerund\": \"Word-level grammar\",\n",
        "  \"Verb_Bare_Inf\": \"Word-level grammar\",\n",
        "  \"Verb_object_bare\": \"Word-level grammar\",\n",
        "  \"Restoration_alter\": \"Word-level grammar\",\n",
        "  \"Verb_part\": \"Word-level grammar\",\n",
        "  \"Get_part\": \"Word-level grammar\",\n",
        "  \"Complex_obj\": \"Word-level grammar\",\n",
        "  \"Verbal_idiom\": \"Word-level grammar\",\n",
        "  \"Prepositional_verb\": \"Word-level grammar\",\n",
        "  \"Dative\": \"Word-level grammar\",\n",
        "  \"Followed_by_a_clause\": \"Word-level grammar\",\n",
        "  \"that_clause\": \"Word-level grammar\",\n",
        "  \"if_whether_clause\": \"Word-level grammar\",\n",
        "  \"that_subj_clause\": \"Word-level grammar\",\n",
        "  \"it_conj_clause\": \"Word-level grammar\",\n",
        "  \"Participial_constr\": \"Word-level grammar\",\n",
        "  \"Infinitive_constr\": \"Word-level grammar\",\n",
        "  \"Gerund_phrase\": \"Word-level grammar\",\n",
        "  \"Nouns\": \"Word-level grammar\",\n",
        "  \"Countable_uncountable\": \"Word-level grammar\",\n",
        "  \"Prepositional_noun\": \"Word-level grammar\",\n",
        "  \"Possessive\": \"Word-level grammar\",\n",
        "  \"Noun_attribute\": \"Word-level grammar\",\n",
        "  \"Noun_inf\": \"Word-level grammar\",\n",
        "  \"Noun_number\": \"Word-level grammar\",\n",
        "  \"Prepositions\": \"Word-level grammar\",\n",
        "  \"Conjunctions\": \"Word-level grammar\",\n",
        "  \"Adjectives\": \"Word-level grammar\",\n",
        "  \"Comparative_adj\": \"Word-level grammar\",\n",
        "  \"Superlative_adj\": \"Word-level grammar\",\n",
        "  \"Prepositional_adjective\": \"Word-level grammar\",\n",
        "  \"Adj_as_collective\": \"Word-level grammar\",\n",
        "  \"Adverbs\": \"Word-level grammar\",\n",
        "  \"Comparative_adv\": \"Word-level grammar\",\n",
        "  \"Superlative_adv\": \"Word-level grammar\",\n",
        "  \"Prepositional_adv\": \"Word-level grammar\",\n",
        "  \"Numerals\": \"Word-level grammar\",\n",
        "  \"Pronouns\": \"Word-level grammar\",\n",
        "  \"Agreement_errors\": \"Complex grammar\",\n",
        "  \"Word_order\": \"Complex grammar\",\n",
        "  \"Standard\": \"Complex grammar\",\n",
        "  \"Emphatic\": \"Complex grammar\",\n",
        "  \"Cleft\": \"Complex grammar\",\n",
        "  \"Interrogative\": \"Complex grammar\",\n",
        "  \"Abs_comp_clause\": \"Complex grammar\",\n",
        "  \"Exclamation\": \"Complex grammar\",\n",
        "  \"Title_structure\": \"Complex grammar\",\n",
        "  \"Note_structure\": \"Complex grammar\",\n",
        "  \"Conditionals\": \"Complex grammar\",\n",
        "  \"Attributes\": \"Complex grammar\",\n",
        "  \"Relative_clause\": \"Complex grammar\",\n",
        "  \"Defining\": \"Complex grammar\",\n",
        "  \"Non_defining\": \"Complex grammar\",\n",
        "  \"Coordinate\": \"Complex grammar\",\n",
        "  \"Attr_participial\": \"Complex grammar\",\n",
        "  \"Lack_par_constr\": \"Complex grammar\",\n",
        "  \"Negation\": \"Complex grammar\",\n",
        "  \"Comparative_constr\": \"Complex grammar\",\n",
        "  \"Numerical\": \"Complex grammar\",\n",
        "  \"Confusion_of_structures\": \"Complex grammar\",\n",
        "  \"Vocabulary\": \"Vocabulary\",\n",
        "  \"Word_choice\": \"Vocabulary\",\n",
        "  \"lex_item_choice\": \"Vocabulary\",\n",
        "  \"Often_confused\": \"Vocabulary\",\n",
        "  \"lex_part_choice\": \"Vocabulary\",\n",
        "  \"Absence_comp_colloc\": \"Vocabulary\",\n",
        "  \"Redundant\": \"Vocabulary\",\n",
        "  \"Derivation\": \"Vocabulary\",\n",
        "  \"Formational_affixes\": \"Vocabulary\",\n",
        "  \"Suffix\": \"Vocabulary\",\n",
        "  \"Prefix\": \"Vocabulary\",\n",
        "  \"Category_confusion\": \"Vocabulary\",\n",
        "  \"Compound_word\": \"Vocabulary\",\n",
        "  \"Discourse\": \"Discourse\",\n",
        "  \"Ref_device\": \"Discourse\",\n",
        "  \"Coherence\": \"Discourse\",\n",
        "  \"Linking_device\": \"Discourse\",\n",
        "  \"Inappropriate_register\": \"Discourse\",\n",
        "  \"Absence_comp_sent\": \"Discourse\",\n",
        "  \"Redundant_comp\": \"Discourse\",\n",
        "  \"Absence_explanation\": \"Discourse\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU1CXIkNp_rd"
      },
      "source": [
        "Обрабатываем корпус:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9OYTRyK8l_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf7cb19-1919-4209-a977-3eee5a5e16ab"
      },
      "source": [
        "%%time\n",
        "\n",
        "pd_dict = OrderedDict()\n",
        "\n",
        "pd_dict[\"path\"] = []\n",
        "pd_dict[\"orig_str\"] = []\n",
        "pd_dict[\"corr_str\"] = []\n",
        "pd_dict[\"ann_label\"] = []\n",
        "pd_dict[\"err_start\"] = []\n",
        "pd_dict[\"err_end\"] = []\n",
        "pd_dict[\"err_type\"] = []\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk('data'):\n",
        "    for file in files:\n",
        "        if file.endswith(\".ann\"):\n",
        "          path = os.path.join(root, file)\n",
        "          try:\n",
        "            patch_list = ann_to_patchlist(path, textpatch_format=True)\n",
        "            for err in patch_list:\n",
        "              if err.err_type in error_typify:\n",
        "                pd_dict[\"path\"].append(path)\n",
        "                pd_dict[\"orig_str\"].append(err.orig_str)\n",
        "                pd_dict[\"corr_str\"].append(err.corr_str)\n",
        "                pd_dict[\"ann_label\"].append(err.name)\n",
        "                pd_dict[\"err_start\"].append(err.start)\n",
        "                pd_dict[\"err_end\"].append(err.end)\n",
        "                pd_dict[\"err_type\"].append(err.err_type)\n",
        "          except Exception as e:\n",
        "            print(\"Failed at\", file, \"with\", str(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.9 s, sys: 533 ms, total: 40.5 s\n",
            "Wall time: 40.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYtwNSQ2qYID"
      },
      "source": [
        "Как много у нас вхождений ошибок?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs-T381dBB19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b7bc73-b03e-409b-c985-6d5fb34550e9"
      },
      "source": [
        "len(pd_dict[\"orig_str\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "203415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOvFl9bOqbI3"
      },
      "source": [
        "Пора положить данные в `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UaKFYtgBQdM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f69a26cb-fed1-4a76-8127-64f3aad0e651"
      },
      "source": [
        "error_df = pd.DataFrame(pd_dict)\n",
        "\n",
        "error_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>orig_str</th>\n",
              "      <th>corr_str</th>\n",
              "      <th>ann_label</th>\n",
              "      <th>err_start</th>\n",
              "      <th>err_end</th>\n",
              "      <th>err_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111660</th>\n",
              "      <td>data/exam/Exam2014/ZEv_36_1.ann</td>\n",
              "      <td>traveled</td>\n",
              "      <td>travelled</td>\n",
              "      <td>T1</td>\n",
              "      <td>96</td>\n",
              "      <td>104</td>\n",
              "      <td>Spelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198258</th>\n",
              "      <td>data/old IELTS/IELTS2016/JSl_34_2.ann</td>\n",
              "      <td>chep</td>\n",
              "      <td>cheap</td>\n",
              "      <td>T2</td>\n",
              "      <td>153</td>\n",
              "      <td>157</td>\n",
              "      <td>Spelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202170</th>\n",
              "      <td>data/old IELTS/IELTS2016/best_works/40_2.ann</td>\n",
              "      <td>but</td>\n",
              "      <td>, and yet</td>\n",
              "      <td>T5</td>\n",
              "      <td>1876</td>\n",
              "      <td>1879</td>\n",
              "      <td>Linking_device</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198745</th>\n",
              "      <td>data/old IELTS/IELTS2016/EKu_67_2.ann</td>\n",
              "      <td>occuping</td>\n",
              "      <td>occupying</td>\n",
              "      <td>T13</td>\n",
              "      <td>1199</td>\n",
              "      <td>1207</td>\n",
              "      <td>Spelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55401</th>\n",
              "      <td>data/exam/Exam2017/VSa_1-138/VSa_76_2.ann</td>\n",
              "      <td>In to conclude</td>\n",
              "      <td>In conclusion</td>\n",
              "      <td>T8</td>\n",
              "      <td>1299</td>\n",
              "      <td>1313</td>\n",
              "      <td>Category_confusion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  ...            err_type\n",
              "111660               data/exam/Exam2014/ZEv_36_1.ann  ...            Spelling\n",
              "198258         data/old IELTS/IELTS2016/JSl_34_2.ann  ...            Spelling\n",
              "202170  data/old IELTS/IELTS2016/best_works/40_2.ann  ...      Linking_device\n",
              "198745         data/old IELTS/IELTS2016/EKu_67_2.ann  ...            Spelling\n",
              "55401      data/exam/Exam2017/VSa_1-138/VSa_76_2.ann  ...  Category_confusion\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ4Lb_hUSdKN"
      },
      "source": [
        "Добавим код для извлечения предложений:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ6dlYeBDKcy"
      },
      "source": [
        "def get_sentence_by_range(start, end, txt, sentencize=sent_tokenize):\n",
        "  sents = sentencize(txt)\n",
        "  r_starts, r_ends = [0], [0]\n",
        "  subst = \"\"\n",
        "  for s in sents:\n",
        "    r_starts.append(txt.find(s, r_ends[-1]))\n",
        "    r_ends.append(r_starts[-1] + len(s))\n",
        "    b, e = r_starts[-1], r_ends[-1]\n",
        "    if b <= end <= e:\n",
        "      break\n",
        "  for b, e in zip(r_starts, r_ends):\n",
        "    if b <= start <= e:\n",
        "      break\n",
        "  return txt[b:r_ends[-1]]\n",
        "\n",
        "def pd_get_context(err_start, err_end, ann_path):\n",
        "  with open(ann_path[:-3] + \"txt\", \"r\", encoding=\"utf-8\") as intext:\n",
        "    text = intext.read()\n",
        "  return get_sentence_by_range(err_start, err_end, text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdBQu8QrSqJa"
      },
      "source": [
        "Эта операция занимает около двух минут, поэтому прикрутим к ней прогрессбар:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRNYioyFMWrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6f400cc73824474c9bf53feb8109231a",
            "632818bb84944ecd80e431818905d211",
            "ac033afaa43e47ceb405a43a247de384",
            "f9cd6248cd08477aa114e728a2ba54cf",
            "0fc0f3d83c2948878028cc0eeed63e03",
            "d8cf936f1c53411bb5c06b372011ac68",
            "338d781a47184a669238bcd05a798619",
            "e87b54dbd0754b7ebd932f5507cf32b1"
          ]
        },
        "outputId": "fb331cdc-36bd-42a4-e0de-4667bf828fb0"
      },
      "source": [
        "error_df[\"context\"] = error_df.progress_apply(lambda x: pd_get_context(x[\"err_start\"], x[\"err_end\"], x[\"path\"]), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f400cc73824474c9bf53feb8109231a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=203415.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s20wi6CyUFyl"
      },
      "source": [
        "Пора проверить – как выглядит наш датасет?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmVFmK8SOasb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5232f552-f6a3-4d14-d6d2-7dba1af8eed3"
      },
      "source": [
        "error_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>orig_str</th>\n",
              "      <th>corr_str</th>\n",
              "      <th>ann_label</th>\n",
              "      <th>err_start</th>\n",
              "      <th>err_end</th>\n",
              "      <th>err_type</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>153141</th>\n",
              "      <td>data/exam/Exam2018/EEr_34_1.ann</td>\n",
              "      <td>, who are overweight</td>\n",
              "      <td>who are overweight</td>\n",
              "      <td>T11</td>\n",
              "      <td>733</td>\n",
              "      <td>753</td>\n",
              "      <td>Defining</td>\n",
              "      <td>Comparing with the boys, who are overweight, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197292</th>\n",
              "      <td>data/old IELTS/IELTS2016/EKu_5_2.ann</td>\n",
              "      <td>thereputation</td>\n",
              "      <td>the reputation</td>\n",
              "      <td>T9</td>\n",
              "      <td>871</td>\n",
              "      <td>884</td>\n",
              "      <td>Spelling</td>\n",
              "      <td>Secondly, the chances to adopt to normal life ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48807</th>\n",
              "      <td>data/exam/Exam2017/ABl/ABl_36_2.ann</td>\n",
              "      <td>help</td>\n",
              "      <td>a help</td>\n",
              "      <td>T14</td>\n",
              "      <td>269</td>\n",
              "      <td>273</td>\n",
              "      <td>Articles</td>\n",
              "      <td>With help of social networks and web-sites peo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141086</th>\n",
              "      <td>data/exam/undefined/AKhr_35_2.ann</td>\n",
              "      <td>law-maker's</td>\n",
              "      <td>law-makers'</td>\n",
              "      <td>T56</td>\n",
              "      <td>1447</td>\n",
              "      <td>1458</td>\n",
              "      <td>Noun_number</td>\n",
              "      <td>To conclude with, it is important to understan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11446</th>\n",
              "      <td>data/2012-2014/esl_01290.ann</td>\n",
              "      <td>can not</td>\n",
              "      <td>cannot</td>\n",
              "      <td>T2</td>\n",
              "      <td>90</td>\n",
              "      <td>97</td>\n",
              "      <td>Spelling</td>\n",
              "      <td>I can not agree that architecture is the mothe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        path  ...                                            context\n",
              "153141       data/exam/Exam2018/EEr_34_1.ann  ...  Comparing with the boys, who are overweight, t...\n",
              "197292  data/old IELTS/IELTS2016/EKu_5_2.ann  ...  Secondly, the chances to adopt to normal life ...\n",
              "48807    data/exam/Exam2017/ABl/ABl_36_2.ann  ...  With help of social networks and web-sites peo...\n",
              "141086     data/exam/undefined/AKhr_35_2.ann  ...  To conclude with, it is important to understan...\n",
              "11446           data/2012-2014/esl_01290.ann  ...  I can not agree that architecture is the mothe...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDMUAru6iBKC"
      },
      "source": [
        "Теперь скачаем два списка дубликатов и таблицу с примером вывода."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNpTqx_c6UVv"
      },
      "source": [
        "!mkdir tables\n",
        "!wget -q https://storage.googleapis.com/ml-bucket-isikus/practice_dup/for_practice.xlsx -P tables\n",
        "!wget -q https://storage.googleapis.com/ml-bucket-isikus/practice_dup/rest_of_duplicates.xlsx -P tables\n",
        "!wget -q https://storage.googleapis.com/ml-bucket-isikus/practice_dup/result_ex_merged.xlsx -P tables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPqFkH7-GusM"
      },
      "source": [
        "Создадим функции для проверки актуальности пары дубликатов и поиска предпоследнего вхождения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-NjvEo-7KDJ"
      },
      "source": [
        "def matches(path1, path2):\n",
        "  try:\n",
        "    with open(path1, \"r\") as intxt:\n",
        "      txt1 = intxt.read()\n",
        "    with open(path2, \"r\") as intxt:\n",
        "      txt2 = intxt.read()\n",
        "    return txt1 == txt2\n",
        "  except:\n",
        "    return False\n",
        "\n",
        "def find_second_last(text, pattern):\n",
        "  return text.rfind(pattern, 0, text.rfind(pattern))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb8UF7zG29V"
      },
      "source": [
        "Наконец, обработаем списки дублирующихся файлов и пропишем необходимое название файла для файла результата:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbczjlwH6gQv"
      },
      "source": [
        "group_1 = pd.read_excel(\"tables/for_practice.xlsx\")\n",
        "group_1[\"Exam2018\"] = \"data/exam/\" + group_1[\"Exam2018\"]\n",
        "group_1[\"Exam2019\"] = \"data/exam/\" + group_1[\"Exam2019\"]\n",
        "group_1[\"Matching\"] = group_1.apply(lambda x: matches(x[\"Exam2018\"], x[\"Exam2019\"]), axis=1)\n",
        "group_1 = group_1.loc[group_1[\"Matching\"]].reset_index(drop=True)\n",
        "group_1[\"Result_Name\"] = group_1[\"Exam2019\"].apply(lambda x: \"Results/Res\" + x[x.find(\"_\"):-4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqIeFvRk9L2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "b766d0f0-8238-4854-b83b-ba4e74cba1a9"
      },
      "source": [
        "group_2 = pd.read_excel(\"tables/rest_of_duplicates.xlsx\")\n",
        "group_2[\"Text1\"] = \"data/exam/\" + group_2[\"Text1\"]\n",
        "group_2[\"Text2\"] = \"data/exam/\" + group_2[\"Text2\"]\n",
        "group_2[\"Matching\"] = group_2.apply(lambda x: matches(x[\"Text1\"], x[\"Text2\"]), axis=1)\n",
        "group_2 = group_2.loc[group_2[\"Matching\"]].reset_index(drop=True)\n",
        "group_2[\"Result_Name\"] = group_2[\"Text2\"].apply(lambda x: \"Results2/Res\" + x[find_second_last(x, \"_\"):-4])\n",
        "\n",
        "group_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text1</th>\n",
              "      <th>Text2</th>\n",
              "      <th>Matching</th>\n",
              "      <th>Result_Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/exam/Exam2019/ABu_143_2.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_215_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_215_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/exam/Exam2019/ABu_143_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_215_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_215_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/exam/Exam2015/KT_17_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_17_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_17_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/exam/Exam2015/KT_10_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_10_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_10_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/exam/Exam2015/KT_10_1.txt</td>\n",
              "      <td>data/exam/Test2015/KT_10_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_10_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>data/exam/Exam2015/KT_14_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_14_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_14_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>data/exam/Exam2015/KT_12_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_12_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_12_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>data/exam/Exam2015/KT_19_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_19_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_19_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>data/exam/Exam2015/KT_14_1.txt</td>\n",
              "      <td>data/exam/Test2015/KT_14_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_14_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>data/exam/Exam2015/KT_19_1.txt</td>\n",
              "      <td>data/exam/Test2015/KT_19_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_19_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Text1  ...         Result_Name\n",
              "0  data/exam/Exam2019/ABu_143_2.txt  ...  Results2/Res_215_2\n",
              "1  data/exam/Exam2019/ABu_143_1.txt  ...  Results2/Res_215_1\n",
              "2    data/exam/Exam2015/KT_17_2.txt  ...   Results2/Res_17_2\n",
              "3    data/exam/Exam2015/KT_10_2.txt  ...   Results2/Res_10_2\n",
              "4    data/exam/Exam2015/KT_10_1.txt  ...   Results2/Res_10_1\n",
              "5    data/exam/Exam2015/KT_14_2.txt  ...   Results2/Res_14_2\n",
              "6    data/exam/Exam2015/KT_12_2.txt  ...   Results2/Res_12_2\n",
              "7    data/exam/Exam2015/KT_19_2.txt  ...   Results2/Res_19_2\n",
              "8    data/exam/Exam2015/KT_14_1.txt  ...   Results2/Res_14_1\n",
              "9    data/exam/Exam2015/KT_19_1.txt  ...   Results2/Res_19_1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3rp2e4gHTcr"
      },
      "source": [
        "output_example = pd.read_excel(\"tables/result_ex_merged.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utLofAhNjvhX"
      },
      "source": [
        "### Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICZenvE-KWNm"
      },
      "source": [
        "У нас есть датафрейм со всеми записями ошибок в REALEC:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "nQ-eA4fZKVoJ",
        "outputId": "e0593f8b-1c6c-40f2-a242-9d6e8fabad73"
      },
      "source": [
        "error_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>orig_str</th>\n",
              "      <th>corr_str</th>\n",
              "      <th>ann_label</th>\n",
              "      <th>err_start</th>\n",
              "      <th>err_end</th>\n",
              "      <th>err_type</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109347</th>\n",
              "      <td>data/exam/Exam2014/DZu_24_1.ann</td>\n",
              "      <td>write</td>\n",
              "      <td>write down</td>\n",
              "      <td>T9</td>\n",
              "      <td>661</td>\n",
              "      <td>666</td>\n",
              "      <td>Absence_comp_colloc</td>\n",
              "      <td>Other Underground railway system I want to wri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116377</th>\n",
              "      <td>data/exam/Exam2014/DAr_4_1.ann</td>\n",
              "      <td>eldery</td>\n",
              "      <td>elderly</td>\n",
              "      <td>T16</td>\n",
              "      <td>943</td>\n",
              "      <td>949</td>\n",
              "      <td>Often_confused</td>\n",
              "      <td>In 2050 the picture will change a little: the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21686</th>\n",
              "      <td>data/exam/Exam2017_Elizaveta/ekl_10_1.ann</td>\n",
              "      <td>raise</td>\n",
              "      <td>rise</td>\n",
              "      <td>T196</td>\n",
              "      <td>338</td>\n",
              "      <td>343</td>\n",
              "      <td>Often_confused</td>\n",
              "      <td>Also, in the S. Asia the percentage of unemplo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16253</th>\n",
              "      <td>data/Exam_practice/OV201617/151-152/st_17_2.ann</td>\n",
              "      <td>from</td>\n",
              "      <td>among</td>\n",
              "      <td>T12</td>\n",
              "      <td>534</td>\n",
              "      <td>538</td>\n",
              "      <td>Prepositions</td>\n",
              "      <td>Alberta stands out from other provinces.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127539</th>\n",
              "      <td>data/exam/Exam2019/ABu_125_1.ann</td>\n",
              "      <td>sudy</td>\n",
              "      <td>study</td>\n",
              "      <td>T2</td>\n",
              "      <td>240</td>\n",
              "      <td>244</td>\n",
              "      <td>Spelling</td>\n",
              "      <td>Overall, the vast majority of the visitors bot...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   path  ...                                            context\n",
              "109347                  data/exam/Exam2014/DZu_24_1.ann  ...  Other Underground railway system I want to wri...\n",
              "116377                   data/exam/Exam2014/DAr_4_1.ann  ...  In 2050 the picture will change a little: the ...\n",
              "21686         data/exam/Exam2017_Elizaveta/ekl_10_1.ann  ...  Also, in the S. Asia the percentage of unemplo...\n",
              "16253   data/Exam_practice/OV201617/151-152/st_17_2.ann  ...           Alberta stands out from other provinces.\n",
              "127539                 data/exam/Exam2019/ABu_125_1.ann  ...  Overall, the vast majority of the visitors bot...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G16cYpbxHEFE"
      },
      "source": [
        "Также нас есть два списка дублирующихся файлов – `group_1` и `group_2`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "swnm4t0SHRZU",
        "outputId": "2dce574a-a843-4e96-b01c-b4b99fd96b90"
      },
      "source": [
        "group_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exam2018</th>\n",
              "      <th>Exam2019</th>\n",
              "      <th>Matching</th>\n",
              "      <th>Result_Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/exam/Exam2018/EEr_66_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_1_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/exam/Exam2018/EEr_66_2.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_1_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_1_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/exam/Exam2018/EEr_5_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_2_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/exam/Exam2018/EEr_5_2.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_2_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_2_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/exam/Exam2018/EEr_13_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_3_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_3_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>data/exam/Exam2018/EEr_225_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_173_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_173_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>data/exam/Exam2018/EEr_50_2.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_28_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_28_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>data/exam/Exam2018/EEr_17_2.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_31_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_31_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>data/exam/Exam2018/EEr_91_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_236_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_236_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>data/exam/Exam2018/EEr_4_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_11_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results/Res_11_2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>256 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Exam2018  ...        Result_Name\n",
              "0     data/exam/Exam2018/EEr_66_1.txt  ...    Results/Res_1_1\n",
              "1     data/exam/Exam2018/EEr_66_2.txt  ...    Results/Res_1_2\n",
              "2      data/exam/Exam2018/EEr_5_1.txt  ...    Results/Res_2_1\n",
              "3      data/exam/Exam2018/EEr_5_2.txt  ...    Results/Res_2_2\n",
              "4     data/exam/Exam2018/EEr_13_1.txt  ...    Results/Res_3_1\n",
              "..                                ...  ...                ...\n",
              "251  data/exam/Exam2018/EEr_225_1.txt  ...  Results/Res_173_1\n",
              "252   data/exam/Exam2018/EEr_50_2.txt  ...   Results/Res_28_2\n",
              "253   data/exam/Exam2018/EEr_17_2.txt  ...   Results/Res_31_2\n",
              "254   data/exam/Exam2018/EEr_91_1.txt  ...  Results/Res_236_2\n",
              "255    data/exam/Exam2018/EEr_4_1.txt  ...   Results/Res_11_2\n",
              "\n",
              "[256 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "wF0hastIHQ77",
        "outputId": "1af2babd-06d0-471a-ff8a-4af29d4299bb"
      },
      "source": [
        "group_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text1</th>\n",
              "      <th>Text2</th>\n",
              "      <th>Matching</th>\n",
              "      <th>Result_Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/exam/Exam2019/ABu_143_2.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_215_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_215_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/exam/Exam2019/ABu_143_1.txt</td>\n",
              "      <td>data/exam/Exam2019/ABu_215_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_215_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/exam/Exam2015/KT_17_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_17_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_17_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/exam/Exam2015/KT_10_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_10_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_10_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/exam/Exam2015/KT_10_1.txt</td>\n",
              "      <td>data/exam/Test2015/KT_10_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_10_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>data/exam/Exam2015/KT_14_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_14_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_14_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>data/exam/Exam2015/KT_12_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_12_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_12_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>data/exam/Exam2015/KT_19_2.txt</td>\n",
              "      <td>data/exam/Test2015/KT_19_2.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_19_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>data/exam/Exam2015/KT_14_1.txt</td>\n",
              "      <td>data/exam/Test2015/KT_14_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_14_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>data/exam/Exam2015/KT_19_1.txt</td>\n",
              "      <td>data/exam/Test2015/KT_19_1.txt</td>\n",
              "      <td>True</td>\n",
              "      <td>Results2/Res_19_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Text1  ...         Result_Name\n",
              "0  data/exam/Exam2019/ABu_143_2.txt  ...  Results2/Res_215_2\n",
              "1  data/exam/Exam2019/ABu_143_1.txt  ...  Results2/Res_215_1\n",
              "2    data/exam/Exam2015/KT_17_2.txt  ...   Results2/Res_17_2\n",
              "3    data/exam/Exam2015/KT_10_2.txt  ...   Results2/Res_10_2\n",
              "4    data/exam/Exam2015/KT_10_1.txt  ...   Results2/Res_10_1\n",
              "5    data/exam/Exam2015/KT_14_2.txt  ...   Results2/Res_14_2\n",
              "6    data/exam/Exam2015/KT_12_2.txt  ...   Results2/Res_12_2\n",
              "7    data/exam/Exam2015/KT_19_2.txt  ...   Results2/Res_19_2\n",
              "8    data/exam/Exam2015/KT_14_1.txt  ...   Results2/Res_14_1\n",
              "9    data/exam/Exam2015/KT_19_1.txt  ...   Results2/Res_19_1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2S78fU-HYO8"
      },
      "source": [
        "**Задание**. Необходимо выбрать из общего датафрейма со всеми ошибками те, которые относятся к файлам-дубликатам, и свести нотации ошибок в каждой паре дубликатов согласно следующему алгоритму:\n",
        "\n",
        "* Если аннотация ошибок из одного файла не пересекается с аннотацией ошибок в другом файле, занести её в соответствующий файл в папке `Results` или `Results2`;\n",
        "* Если пара аннотаций ошибок в файлах-дубликатах полностью пересекаются и полностью совпадают (у `err1` и `err2` совпадают `err_start`, `err_end`, `err_type` и `corr_str`), также занести любую из идентичных аннотаций в соответствующий файл в папке `Results` или `Results2`;\n",
        "* Если же области ошибок пересекаются частично, или если они пересекаются полностью, но хотя бы одно из значений `err_start`, `err_end`, `err_type` или `corr_str` у ошибок не совпадает, такие случаи следует занести в отдельный датафрейм расхождения в аннотациях."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4uR74yIJTOw"
      },
      "source": [
        "Понятие *«аннотации не пересекаются»* означает, что для данной записи `err1` в `file1` нет такой записи `err2` в `file2`, чтобы `range(err2.start, err2.end)` пересекался с аналогичным `range` для записи `err1`. Это можно проверить функцией `range_intersect`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvpSi1LIHUQw"
      },
      "source": [
        "def get_name_from_path(st):\n",
        "  end = 0\n",
        "  start = 0\n",
        "  for i in range(len(st)-1,0,-1):\n",
        "    if st[i]=='.':\n",
        "      end = i\n",
        "    if st[i]=='/':\n",
        "      start = i + 1\n",
        "      break\n",
        "  return st[start:end]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_EYOOPhKvFF"
      },
      "source": [
        "error_df['FileName'] = error_df['path'].apply(get_name_from_path)\n",
        "group_1['FileName1'] = group_1['Exam2018'].apply(get_name_from_path)\n",
        "group_1['FileName2'] = group_1['Exam2019'].apply(get_name_from_path)\n",
        "group_2['FileName1'] = group_2['Text1'].apply(get_name_from_path)\n",
        "group_2['FileName2'] = group_2['Text2'].apply(get_name_from_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-0iikrR-3F1"
      },
      "source": [
        "def patchobj_to_brat_ann(patch):\n",
        "  p = patch\n",
        "  h = str(hash(repr(p)))\n",
        "  T = \"T\" + h[-4:]\n",
        "  A = \"A\" + h[-8:-4]\n",
        "  retstr = \"{}\\t{} {} {}\\t{}\\n\".format(T, p[\"err_type\"], p[\"err_start\"], p[\"err_end\"], p[\"orig_str\"])\n",
        "  if patch.corr_str == \"\":\n",
        "    retstr += \"{}\\tDelete {}\".format(A, T)\n",
        "  else:\n",
        "    retstr += \"{}\\tAnnotatorNotes {}\\t{}\".format(\"#\"+T[1:], T, p[\"corr_str\"])\n",
        "  return retstr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oykO9iqySbUK"
      },
      "source": [
        "output = pd.DataFrame(columns=output_example.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqLLyStjIhb_"
      },
      "source": [
        "def range_intersect(range1, range2):\n",
        "  _1 = set(range1)\n",
        "  _12 = _1.intersection(range2)\n",
        "  return len(_12) > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8TpIOWNm7Sx",
        "outputId": "dc04e4fc-66da-49ca-a53d-0d94e81e357b"
      },
      "source": [
        "!mkdir Results Results2\n",
        "count=0\n",
        "for index, row in group_1.iterrows():\n",
        "\n",
        "  err_1 = error_df.loc[error_df['FileName']==row['FileName1']]\n",
        "  err_2 = error_df.loc[error_df['FileName']==row['FileName2']]\n",
        "  res = \"\"\n",
        "\n",
        "  for i,r in err_1.iterrows():\n",
        "    flag = True\n",
        "    for j,k in err_2.iterrows():\n",
        "      if range_intersect(range(r.err_start,r.err_end),range(k.err_start,k.err_end)) or (r.err_start==k.err_start and r.err_end==k.err_end and (r.err_type!=k.err_typy or r.corr_str!=k.corr_str)):\n",
        "        flag=False\n",
        "    if flag:\n",
        "      res+=patchobj_to_brat_ann(r)\n",
        "    else:\n",
        "       output.loc[count]=[r.path,row['Result_Name'],r.ann_label,range(r.err_start,r.err_end),r.err_type,r.orig_str,r.corr_str,r.context]\n",
        "       count+=1\n",
        "  for i,r in err_2.iterrows():\n",
        "    flag = True\n",
        "    for j,k in err_1.iterrows():\n",
        "      if range_intersect(range(r.err_start,r.err_end),range(k.err_start,k.err_end)) or (r.err_start==k.err_start and r.err_end==k.err_end and (r.err_type!=k.err_typy or r.corr_str!=k.corr_str)):\n",
        "        flag=False\n",
        "    if flag:\n",
        "      res+=patchobj_to_brat_ann(r)\n",
        "    else:\n",
        "      output.loc[count]=[r.path,row['Result_Name'],r.ann_label,range(r.err_start,r.err_end),r.err_type,r.orig_str,r.corr_str,r.context]\n",
        "      count+=1\n",
        "  !cp {row['Exam2018']} {row['Result_Name']+\".txt\"}\n",
        "  !echo {\"\\\"\"+res+\"\\\"\"} > {row['Result_Name'] + \".ann\"}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T2995\tPunctuation 467 468\t'\n",
            "#2995\tAnnotatorNotes T2995\tT9748 Noun_number 198 209 female ones\n",
            "/bin/bash: line 6: A9046: command not found\n",
            "T9416\tArticles 33 43\tthe family\n",
            "#9416\tAnnotatorNotes T9416\tfamilyT0125\tSuperlative_adj 52 59\tgreater\n",
            "#0125\tAnnotatorNotes T0125\tgreatestT8484\tArticles 184 194\tthe family\n",
            "#8484\tAnnotatorNotes T8484\tfamilyT7267\tArticles 342 352\tthe family\n",
            "#7267\tAnnotatorNotes T7267\tfamilyT1569\tPunctuation 432 435\twhy\n",
            "#1569\tAnnotatorNotes T1569\twhyT1179\tSuperlative_adj 1023 1030\tgreater\n",
            "#1179\tAnnotatorNotes T1179\tgreatestT7962\tInappropriate_register 1117 1125\ta lot of\n",
            "#7962\tAnnotatorNotes T7962\tmanyT4898\tInappropriate_register 1183 1187\tkids\n",
            "#4898\tAnnotatorNotes T4898\tchildrenT3489\tArticles 1288 1297\tstreets\n",
            "#3489\tAnnotatorNotes T3489\tthe streetT8954 Noun_number 1288 1297 streets\n",
            "/bin/bash: line 19: A8756: command not found\n",
            "/bin/bash: line 20: A0527: command not found\n",
            "/bin/bash: line 22: A0608: command not found\n",
            "/bin/bash: line 23: A1627: command not found\n",
            "/bin/bash: line 24: A4132: command not found\n",
            "T3720\tRedundant_comp 288 290\tis\n",
            "A0084\tDelete T3720T5666\tPunctuation 379 383\tAlso\n",
            "#5666\tAnnotatorNotes T5666\tAlso,T2703\tPrefix 537 541\tlike\n",
            "#2703\tAnnotatorNotes T2703\talikeT1776\tPunctuation 734 738\tlove\n",
            "#1776\tAnnotatorNotes T1776\tlove,T4088\tPunctuation 823 830\tstudies\n",
            "#4088\tAnnotatorNotes T4088\tstudies,T9507\tPunctuation 878 886\tscience,\n",
            "#9507\tAnnotatorNotes T9507\tscience,T1370\tPunctuation 1072 1083\tsoul. While\n",
            "#1370\tAnnotatorNotes T1370\tsoul, whileT8388\tOften_confused 1361 1364\tnot\n",
            "#8388\tAnnotatorNotes T8388\tnoT1378\tAgreement_errors 1623 1627\tneed\n",
            "#1378\tAnnotatorNotes T1378\tneedsT1699\tPrepositions 0 2\tIn\n",
            "#1699\tAnnotatorNotes T1699\tAtT4442\tPunctuation 12 13\t,\n",
            "A2418\tDelete T4442T1672\tlex_item_choice 129 136\topinion\n",
            "#1672\tAnnotatorNotes T1672\tissueT1419\tLack_par_constr 373 377\twalk\n",
            "#1419\tAnnotatorNotes T1419\tto walkT3398\tRef_device 495 498\this\n",
            "#3398\tAnnotatorNotes T3398\titsT5500\tPossessive 635 654\tchild's development\n",
            "#5500\tAnnotatorNotes T5500\tthe development of a childT5767\tAgreement_errors 770 776\tlearns\n",
            "#5767\tAnnotatorNotes T5767\tlearnT5463\tArticles 790 802\tthe problems\n",
            "#5463\tAnnotatorNotes T5463\tproblemsT3305\tAgreement_errors 849 854\ttakes\n",
            "#3305\tAnnotatorNotes T3305\ttakeT1303\tlex_item_choice 961 970\timportant\n",
            "#1303\tAnnotatorNotes T1303\tviableT3701\tRedundant_comp 1048 1053\thuman\n",
            "A8809\tDelete T3701T4870\tArticles 1084 1093\tinfluence\n",
            "#4870\tAnnotatorNotes T4870\tthe influenceT1070\tArticles 1099 1106\toutside\n",
            "#1070\tAnnotatorNotes T1070\tthe outsideT0292\tAbsence_comp_sent 1120 1127\tto live\n",
            "#0292\tAnnotatorNotes T0292\thow to liveT5946\tPronouns 1131 1135\tthat\n",
            "#5946\tAnnotatorNotes T5946\tthisT2832\tPunctuation 1257 1261\tlife\n",
            "#2832\tAnnotatorNotes T2832\tlife,T5872\tTense_choice 1398 1406\twould be\n",
            "#5872\tAnnotatorNotes T5872\tisT0884\tConjunctions 1480 1484\twhat\n",
            "#0884\tAnnotatorNotes T0884\twhichT4474\tArticles 1515 1524\tinfluence\n",
            "#4474\tAnnotatorNotes T4474\tthe influenceT2419\tArticles 1530 1537\toutside\n",
            "#2419\tAnnotatorNotes T2419\tthe outsideT0664\tPunctuation 1545 1551\twork\n",
            "#0664\tAnnotatorNotes T0664\tworkT5516 Pronouns 1578 1582 that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz_bLy4wkKkf"
      },
      "source": [
        "for index, row in group_2.iterrows():\n",
        "\n",
        "  err_1 = error_df.loc[error_df['FileName']==row['FileName1']]\n",
        "  err_2 = error_df.loc[error_df['FileName']==row['FileName2']]\n",
        "  res = \"\"\n",
        "\n",
        "  for i,r in err_1.iterrows():\n",
        "    flag = True\n",
        "    for j,k in err_2.iterrows():\n",
        "      if range_intersect(range(r.err_start,r.err_end),range(k.err_start,k.err_end)) or (r.err_start==k.err_start and r.err_end==k.err_end and (r.err_type!=k.err_typy or r.corr_str!=k.corr_str)):\n",
        "        flag=False\n",
        "    if flag:\n",
        "      res+=patchobj_to_brat_ann(r)\n",
        "    else:\n",
        "       output.loc[count]=[r.path,row['Result_Name'],r.ann_label,range(r.err_start,r.err_end),r.err_type,r.orig_str,r.corr_str,r.context]\n",
        "       count+=1\n",
        "  for i,r in err_2.iterrows():\n",
        "    flag = True\n",
        "    for j,k in err_1.iterrows():\n",
        "      if range_intersect(range(r.err_start,r.err_end),range(k.err_start,k.err_end)) or (r.err_start==k.err_start and r.err_end==k.err_end and (r.err_type!=k.err_typy or r.corr_str!=k.corr_str)):\n",
        "        flag=False\n",
        "    if flag:\n",
        "      res+=patchobj_to_brat_ann(r)\n",
        "    else:\n",
        "      output.loc[count]=[r.path,row['Result_Name'],r.ann_label,range(r.err_start,r.err_end),r.err_type,r.orig_str,r.corr_str,r.context]\n",
        "      count+=1\n",
        "  !cp {row['Text1']} {row['Result_Name']+\".txt\"}\n",
        "  !echo {\"\\\"\"+res+\"\\\"\"} > {row['Result_Name'] + \".ann\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BCdwpGcu4ek"
      },
      "source": [
        "это для очищения папок для тестов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3kf0W4XuFdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b181d749-4074-4d71-a39d-c0551d5bad87"
      },
      "source": [
        "os.chdir(\"../\")\n",
        "files = os.listdir()\n",
        "data = []\n",
        "for file in files:\n",
        "    !rm {file}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'run': Is a directory\n",
            "rm: cannot remove 'var': Is a directory\n",
            "rm: cannot remove 'mnt': Is a directory\n",
            "rm: cannot remove 'lib64': Is a directory\n",
            "rm: cannot remove 'root': Is a directory\n",
            "rm: cannot remove 'opt': Is a directory\n",
            "rm: cannot remove 'etc': Is a directory\n",
            "rm: cannot remove 'bin': Is a directory\n",
            "rm: cannot remove 'media': Is a directory\n",
            "rm: cannot remove 'srv': Is a directory\n",
            "rm: cannot remove 'boot': Is a directory\n",
            "rm: cannot remove 'dev': Is a directory\n",
            "rm: cannot remove 'home': Is a directory\n",
            "rm: cannot remove 'tmp': Is a directory\n",
            "rm: cannot remove 'proc': Is a directory\n",
            "rm: cannot remove 'usr': Is a directory\n",
            "rm: cannot remove 'sys': Is a directory\n",
            "rm: cannot remove 'sbin': Is a directory\n",
            "rm: cannot remove 'lib': Is a directory\n",
            "rm: cannot remove 'content': Is a directory\n",
            "rm: cannot remove 'tools': Is a directory\n",
            "rm: cannot remove 'datalab': Is a directory\n",
            "rm: cannot remove 'swift': Is a directory\n",
            "rm: cannot remove 'tensorflow-1.15.2': Is a directory\n",
            "rm: cannot remove 'lib32': Is a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEF3vkc5u31X"
      },
      "source": [
        "output.to_excel(\"output.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psfnhso0VtZL",
        "outputId": "5af88ff8-1b5c-4925-db39-f1fa9d887d62"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ZEYnxjMKg3"
      },
      "source": [
        "Переводить строки из датафрейма в записи в итоговом файле `.ann` следует с помощью следующей функции:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZYJ67ZmMs7C"
      },
      "source": [
        "Пример:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "1C_GN5XI-r2s",
        "outputId": "9d27f66c-0bb1-471e-a41d-a3c23756a569"
      },
      "source": [
        "error_df.loc[9349]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "path                           data/exam/Exam2019/ABu_13_1.ann\n",
              "orig_str                                            the appeal\n",
              "corr_str                                        the popularity\n",
              "ann_label                                                  T13\n",
              "err_start                                                  699\n",
              "err_end                                                    709\n",
              "err_type                                           Word_choice\n",
              "context      Concerning the appeal of regular physical acti...\n",
              "Name: 9349, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "mLcEiM0MAAKA",
        "outputId": "04994e08-a519-4280-dbff-d44f5b9047e2"
      },
      "source": [
        "print(patchobj_to_brat_ann(error_df.loc[9349]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T2427\tWord_choice 699 709\tthe appeal\n",
            "#2427\tAnnotatorNotes T2427\tthe popularity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHBRadepNXdE"
      },
      "source": [
        "Сведённые файлы для дубликатов из `group_1` должны называться согласно значению в столбце `Result_Name` и лежать в папке `Results`; для `group_2`, соответственно, результаты должны лежать в папке `Results2`. В папке должны быть тексты эссе (без изменений) и сведённые файлы аннотаций. Например, для вхождения `Results/Res_1_1` в папке `Results` должен появиться текстовый файл `Res_1_1.txt` с текстом эссе и файл аннотации `Res_1_1.ann` со сведёнными аннотациями."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pKWJ6I7Mu0B"
      },
      "source": [
        "Отдельный датафрейм расхождения в аннотациях должен выглядеть следующим образом (можно сделать два разных для `group_1` и `group_2`, а можно положить всё в один):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "kwLZmgxiHShE",
        "outputId": "4c0aef0e-217b-41cd-c32e-1f00148b40e3"
      },
      "source": [
        "output_example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duplicate_path</th>\n",
              "      <th>resulting_path</th>\n",
              "      <th>ann_label</th>\n",
              "      <th>ann_range</th>\n",
              "      <th>err_type</th>\n",
              "      <th>orig_str</th>\n",
              "      <th>corr_str</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/exam/Exam2019/ABu_4_1.ann</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "      <td>T4</td>\n",
              "      <td>312 325</td>\n",
              "      <td>Tense_choice</td>\n",
              "      <td>was increased</td>\n",
              "      <td>was increasing</td>\n",
              "      <td>During the whole period the number of children...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/exam/Exam2018/EEr_49_1.ann</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "      <td>T4</td>\n",
              "      <td>312 325</td>\n",
              "      <td>Tense_form</td>\n",
              "      <td>was increased</td>\n",
              "      <td>was increasing</td>\n",
              "      <td>During the whole period the number of children...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/exam/Exam2019/ABu_4_1.ann</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "      <td>T6</td>\n",
              "      <td>497 514</td>\n",
              "      <td>Tense_choice</td>\n",
              "      <td>were also changed</td>\n",
              "      <td>was also changing</td>\n",
              "      <td>The amount of children who did different kinds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/exam/Exam2018/EEr_49_1.ann</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "      <td>T5</td>\n",
              "      <td>497 514</td>\n",
              "      <td>Voice</td>\n",
              "      <td>were also changed</td>\n",
              "      <td>has also changed</td>\n",
              "      <td>The amount of children who did different kinds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/exam/Exam2019/ABu_4_1.ann</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "      <td>T12</td>\n",
              "      <td>497 514</td>\n",
              "      <td>Agreement_errors</td>\n",
              "      <td>were also changed</td>\n",
              "      <td>was also changing</td>\n",
              "      <td>The amount of children who did different kinds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>data/exam/Exam2018/EEr_49_1.ann</td>\n",
              "      <td>Results/Res_1_1</td>\n",
              "      <td>T8</td>\n",
              "      <td>497 514</td>\n",
              "      <td>Agreement_errors</td>\n",
              "      <td>were also changed</td>\n",
              "      <td>has also changed</td>\n",
              "      <td>The amount of children who did different kinds...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    duplicate_path  ...                                            context\n",
              "0   data/exam/Exam2019/ABu_4_1.ann  ...  During the whole period the number of children...\n",
              "1  data/exam/Exam2018/EEr_49_1.ann  ...  During the whole period the number of children...\n",
              "2   data/exam/Exam2019/ABu_4_1.ann  ...  The amount of children who did different kinds...\n",
              "3  data/exam/Exam2018/EEr_49_1.ann  ...  The amount of children who did different kinds...\n",
              "4   data/exam/Exam2019/ABu_4_1.ann  ...  The amount of children who did different kinds...\n",
              "5  data/exam/Exam2018/EEr_49_1.ann  ...  The amount of children who did different kinds...\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsr9H_P9OQlJ"
      },
      "source": [
        "В качестве результата выполнения задания нужно прислать [мне](https://vk.com/itorubarov) (Ване) ссылки на загруженные на Гугл-диск архивы папок `Results` и `Results2`, а также датафрейм расхождений `output`, сохранённый как таблица Excel, и ссылку на тетрадку с кодом (не забыв открыть ко всему доступ!).\n",
        "\n",
        "Привожу пример кода архивирования, сохранения таблицы как xlsx-файла и загрузки всего на гугл-диск. Допустим, в папках `Results` и `Results2` всё готово, и собран единый датафрейм расхождений `output` – тогда заархивировать, сохранить и загрузить всё это можно так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMbX8oH1nS_g"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9LhPeLLoFiT",
        "outputId": "6c052d15-f9dd-47cc-c086-8ea5e2cd550c"
      },
      "source": [
        "# архивируем Results\n",
        "!zip -q -r dedup_results.zip Results\n",
        "\n",
        "# архивируем Results2\n",
        "!zip -q -r dedup_results2.zip Results2\n",
        "\n",
        "# сохраняем датафрейм output в формате Excel\n",
        "output.to_excel(\"output.xlsx\", index=False)\n",
        "\n",
        "# загружаем всё на свой гугл-диск\n",
        "!cp dedup_results.zip /content/gdrive/My\\ Drive/dedup_results.zip\n",
        "!cp dedup_results2.zip /content/gdrive/My\\ Drive/dedup_results2.zip\n",
        "!cp dedup_output.xlsx /content/gdrive/My\\ Drive/dedup_output.xlsx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "zip error: Nothing to do! (try: zip -q -r dedup_results.zip . -i Results)\n",
            "\n",
            "zip error: Nothing to do! (try: zip -q -r dedup_results2.zip . -i Results2)\n",
            "cp: cannot stat 'dedup_results.zip': No such file or directory\n",
            "cp: cannot stat 'dedup_results2.zip': No such file or directory\n",
            "cp: cannot stat 'dedup_output.xlsx': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}